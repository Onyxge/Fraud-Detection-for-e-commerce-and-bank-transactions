{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set visual style\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 1. Load Data\n",
    "try:\n",
    "    df = pd.read_csv('../data/raw/Fraud_Data.csv')\n",
    "    print(\"✅ Fraud_Data loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ File not found. Check path.\")\n",
    "\n",
    "# 2. Data Cleaning & Quality Check [cite: 113-116]\n",
    "print(f\"Initial Shape: {df.shape}\")\n",
    "\n",
    "# A. Convert Timestamps to Datetime objects\n",
    "df['signup_time'] = pd.to_datetime(df['signup_time'])\n",
    "df['purchase_time'] = pd.to_datetime(df['purchase_time'])\n",
    "\n",
    "# B. Check for Duplicates\n",
    "dupes = df.duplicated().sum()\n",
    "if dupes > 0:\n",
    "    print(f\"⚠️ Found {dupes} duplicates. Removing them...\")\n",
    "    df.drop_duplicates(inplace=True)\n",
    "else:\n",
    "    print(\"✅ No duplicates found.\")\n",
    "\n",
    "# C. Check for Missing Values\n",
    "missing = df.isnull().sum()\n",
    "print(f\"\\nMissing Values:\\n{missing[missing > 0]}\")\n",
    "# Note: If no missing values print, we are good.\n",
    "# If 'device_id' or others have missing, we must decide to drop or impute.\n",
    "\n",
    "# 3. Exploratory Data Analysis (EDA)\n",
    "\n",
    "# A. Class Distribution (The Imbalance) [cite: 120]\n",
    "fraud_count = df['class'].value_counts()\n",
    "fraud_pct = df['class'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"\\n--- Class Distribution ---\")\n",
    "print(fraud_count)\n",
    "print(f\"\\nFraud Rate: {fraud_pct[1]:.2f}%\")\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "print(\"\\nMissing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDuplicate rows:\")\n",
    "print(df.duplicated().sum())\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert timestamps\n",
    "df[\"signup_time\"] = pd.to_datetime(df[\"signup_time\"], errors=\"coerce\")\n",
    "df[\"purchase_time\"] = pd.to_datetime(df[\"purchase_time\"], errors=\"coerce\")\n",
    "\n",
    "print(\"\\nNull timestamps after parsing:\")\n",
    "print(df[[\"signup_time\", \"purchase_time\"]].isnull().sum())\n",
    "# Time sanity: purchase should not happen before signup\n",
    "invalid_time_order = df[df[\"purchase_time\"] < df[\"signup_time\"]]\n",
    "\n",
    "print(f\"\\nTransactions where purchase_time < signup_time: {len(invalid_time_order)}\")\n",
    "\n",
    "if len(invalid_time_order) > 0:\n",
    "    display(invalid_time_order.head())"
   ],
   "id": "8dd2a7a4526d253a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df[\"time_since_signup_seconds\"] = (\n",
    "    df[\"purchase_time\"] - df[\"signup_time\"]\n",
    ").dt.total_seconds()\n",
    "\n",
    "print(\"\\nTime since signup summary (seconds):\")\n",
    "print(df[\"time_since_signup_seconds\"].describe())\n",
    "\n",
    "print(\"\\nNegative or zero time_since_signup values:\")\n",
    "print((df[\"time_since_signup_seconds\"] <= 0).sum())\n"
   ],
   "id": "b6174a1170cbc879"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='class', data=df)\n",
    "plt.title('Class Distribution: Fraud (1) vs Non-Fraud (0)')\n",
    "plt.show()\n",
    "\n",
    "# B. Univariate Analysis: Purchase Value [cite: 118]\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(df['purchase_value'], bins=50, kde=True)\n",
    "plt.title('Distribution of Purchase Value')\n",
    "plt.show()\n",
    "\n",
    "# C. Bivariate Analysis: Purchase Value vs Class [cite: 119]\n",
    "# Do fraudsters spend more?\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(x='class', y='purchase_value', data=df)\n",
    "plt.title('Purchase Value by Class')\n",
    "plt.show()\n",
    "\n",
    "# D. Temporal Analysis (Quick check on time)\n",
    "# Is there a gap between signup and purchase?\n",
    "df['time_diff'] = (df['purchase_time'] - df['signup_time']).dt.total_seconds() / 3600 # in hours\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(data=df, x='time_diff', hue='class', kde=True, bins=50, common_norm=False)\n",
    "plt.title('Time Difference (Signup vs Purchase) by Class')\n",
    "plt.xlim(0, 48) # Zooming in on the first 48 hours to see immediate attacks\n",
    "plt.show()"
   ],
   "id": "ea2d6c9cb17fae74"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 4. Categorical Analysis ---\n",
    "# We want to see if the Fraud Rate (Class 1) is higher for certain browsers or sources.\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "# Browser Analysis\n",
    "sns.countplot(x='browser', hue='class', data=df, ax=axes[0])\n",
    "axes[0].set_title('Fraud by Browser')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Source Analysis\n",
    "sns.countplot(x='source', hue='class', data=df, ax=axes[1])\n",
    "axes[1].set_title('Fraud by Source')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- 5. \"Shared Entity\" Analysis (Critical for Fraud) ---\n",
    "# Fraudsters often use the same device or IP to make multiple fake accounts.\n",
    "\n",
    "# A. Devices used by multiple users\n",
    "device_counts = df.groupby('device_id')['user_id'].count()\n",
    "print(\"\\n--- Device ID Analysis ---\")\n",
    "print(f\"Total unique devices: {len(device_counts)}\")\n",
    "print(f\"Devices used by > 1 user: {len(device_counts[device_counts > 1])}\")\n",
    "\n",
    "# Let's plot the fraud rate against the number of users per device\n",
    "# We merge the counts back to the main df\n",
    "df['device_user_count'] = df['device_id'].map(device_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='device_user_count', y='class', data=df, errorbar=None)\n",
    "plt.title('Fraud Rate vs. Number of Users on Same Device')\n",
    "plt.xlabel('Number of Users Sharing Device')\n",
    "plt.ylabel('Fraud Probability')\n",
    "plt.show()\n",
    "\n",
    "# B. IPs used by multiple users\n",
    "ip_counts = df.groupby('ip_address')['user_id'].count()\n",
    "df['ip_user_count'] = df['ip_address'].map(ip_counts)\n",
    "\n",
    "print(\"\\n--- IP Address Analysis ---\")\n",
    "print(f\"IPs used by > 1 user: {len(ip_counts[ip_counts > 1])}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x='ip_user_count', y='class', data=df, errorbar=None)\n",
    "plt.title('Fraud Rate vs. Number of Users on Same IP')\n",
    "plt.xlabel('Number of Users Sharing IP')\n",
    "plt.ylabel('Fraud Probability')\n",
    "plt.show()\n",
    "\n",
    "# --- 6. Age Analysis ---\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.kdeplot(data=df[df['class']==0]['age'], label='Not Fraud', fill=True)\n",
    "sns.kdeplot(data=df[df['class']==1]['age'], label='Fraud', fill=True)\n",
    "plt.title('Age Distribution by Class')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "b500580230a0973c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Ensure timestamps are datetime\n",
    "df[\"signup_time\"] = pd.to_datetime(df[\"signup_time\"])\n",
    "df[\"purchase_time\"] = pd.to_datetime(df[\"purchase_time\"])\n",
    "\n",
    "# Time-based features\n",
    "df[\"hour_of_day\"] = df[\"purchase_time\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"purchase_time\"].dt.dayofweek  # 0=Monday\n",
    "\n",
    "df[[\"hour_of_day\", \"day_of_week\"]].describe()\n",
    "\n",
    "#visualize fraud patterns\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x=\"hour_of_day\", hue=\"class\", data=df)\n",
    "plt.title(\"Fraud Distribution by Hour of Day\")\n",
    "plt.show()\n"
   ],
   "id": "dbf1e4928e248209"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.kdeplot(\n",
    "    df[df[\"class\"] == 0][\"time_since_signup_seconds\"],\n",
    "    label=\"Legitimate\",\n",
    "    fill=True\n",
    ")\n",
    "sns.kdeplot(\n",
    "    df[df[\"class\"] == 1][\"time_since_signup_seconds\"],\n",
    "    label=\"Fraud\",\n",
    "    fill=True\n",
    ")\n",
    "plt.title(\"Time Since Signup Distribution by Class\")\n",
    "plt.xlabel(\"Seconds Since Signup\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "id": "38e41ac1d5390b19"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# --- 6. Geolocation Analysis ---\n",
    "\n",
    "# 1. Load the IP dataset\n",
    "try:\n",
    "    ip_df = pd.read_csv('../data/raw/IpAddress_to_Country.csv')\n",
    "    print(\"✅ IpAddress_to_Country loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"❌ File not found.\")\n",
    "\n",
    "# 2. Convert IP addresses to integers for accurate comparison [cite: 380]\n",
    "# Note: IP addresses in Fraud_Data are floats, we convert to int.\n",
    "df['ip_address'] = df['ip_address'].astype(int)\n",
    "ip_df['lower_bound_ip_address'] = ip_df['lower_bound_ip_address'].astype(int)\n",
    "ip_df['upper_bound_ip_address'] = ip_df['upper_bound_ip_address'].astype(int)\n",
    "\n",
    "# 3. Efficient Merge using merge_asof\n",
    "# We must sort both dataframes by the key we are merging on (IP)\n",
    "df = df.sort_values('ip_address')\n",
    "ip_df = ip_df.sort_values('lower_bound_ip_address')\n",
    "\n",
    "# merge_asof matches the 'ip_address' to the nearest 'lower_bound_ip_address'\n",
    "# that is less than or equal to the user's IP.\n",
    "df_merged = pd.merge_asof(\n",
    "    df,\n",
    "    ip_df,\n",
    "    left_on='ip_address',\n",
    "    right_on='lower_bound_ip_address',\n",
    "    direction='backward'\n",
    ")\n",
    "\n",
    "# 4. Filter for validity\n",
    "# merge_asof finds the *nearest* lower bound. We must ensure the IP is ALSO\n",
    "# less than the upper bound of that country.\n",
    "mask = (df_merged['ip_address'] <= df_merged['upper_bound_ip_address'])\n",
    "\n",
    "# Create the final country column\n",
    "df_merged['country'] = df_merged.loc[mask, 'country']\n",
    "\n",
    "# Fill valid unmatched IPs with \"Unknown\"\n",
    "df_merged['country'].fillna('Unknown', inplace=True)\n",
    "\n",
    "# 5. Quick Check\n",
    "print(f\"\\nmerged shape: {df_merged.shape}\")\n",
    "print(f\"Countries found: {df_merged['country'].nunique()}\")\n",
    "print(\"\\nTop 5 Countries by Transaction Count:\")\n",
    "print(df_merged['country'].value_counts().head())\n",
    "\n",
    "# 6. Visualize Fraud by Country (Top 10) [cite: 382]\n",
    "# We look at countries with at least 50 transactions to avoid noise\n",
    "country_stats = df_merged.groupby('country').agg(\n",
    "    total_transactions=('class', 'count'),\n",
    "    fraud_rate=('class', 'mean')\n",
    ").reset_index()\n",
    "\n",
    "country_stats = country_stats[country_stats['total_transactions'] > 50]\n",
    "top_fraud_countries = country_stats.sort_values(by='fraud_rate', ascending=False).head(10)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='fraud_rate', y='country', data=top_fraud_countries, palette='Reds_r')\n",
    "plt.title('Top 10 High-Risk Countries (by Fraud Rate)')\n",
    "plt.xlabel('Fraud Rate')\n",
    "plt.show()"
   ],
   "id": "bdb938d4d8420c2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "save_path = '../data/processed/fraud_data_merged.csv'\n",
    "\n",
    "# Save to CSV\n",
    "# index=False is crucial so we don't generate an extra column\n",
    "df_merged.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"✅ Intermediate data saved to: {save_path}\")\n",
    "print(f\"Shape: {df_merged.shape}\")"
   ],
   "id": "8691012fb565658a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
